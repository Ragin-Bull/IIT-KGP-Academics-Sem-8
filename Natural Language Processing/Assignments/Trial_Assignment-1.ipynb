{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3b9449",
   "metadata": {},
   "source": [
    "# Task -1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac308b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a025a26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  doc_id                                           doc_text\n",
       "0           0       1  What is the step by step guide to invest in sh...\n",
       "1           1       2  What is the step by step guide to invest in sh...\n",
       "2           2       3  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "3           3       4  What would happen if the Indian government sto...\n",
       "4           4       5  How can I increase the speed of my internet co..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Query_Doc/docs.csv\")\n",
    "queries = pd.read_csv(\"./Query_Doc/queries.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc0aabcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4584</td>\n",
       "      <td>How can ask questions using photos?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6588</td>\n",
       "      <td>What is Atal Pension Yojana? What are its bene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10113</td>\n",
       "      <td>Where is starch digested? How is it digested?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7957</td>\n",
       "      <td>What is a conjecture? What are some examples?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5498</td>\n",
       "      <td>What can India do to support the people suffer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  query_id                                         query_text\n",
       "0           0      4584                How can ask questions using photos?\n",
       "1           1      6588  What is Atal Pension Yojana? What are its bene...\n",
       "2           2     10113      Where is starch digested? How is it digested?\n",
       "3           3      7957      What is a conjecture? What are some examples?\n",
       "4           4      5498  What can India do to support the people suffer..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc8c40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206be121",
   "metadata": {},
   "source": [
    "### 1. Preprocessing of the docs and queries - removing the characters other than alphanumerics or whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4501989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    What is the step by step guide to invest in sh...\n",
      "1    What is the step by step guide to invest in sh...\n",
      "2    What is the story of Kohinoor  Koh i Noor  Dia...\n",
      "3    What would happen if the Indian government sto...\n",
      "4    How can I increase the speed of my internet co...\n",
      "Name: pure, dtype: object\n",
      "0                  How can ask questions using photos \n",
      "1    What is Atal Pension Yojana  What are its bene...\n",
      "2        Where is starch digested  How is it digested \n",
      "3        What is a conjecture  What are some examples \n",
      "4    What can India do to support the people suffer...\n",
      "Name: pure, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def purify_docs(data):\n",
    "    purified_doc = re.sub(r'[^a-zA-Z0-9\\s]', ' ', data)\n",
    "    return purified_doc\n",
    "\n",
    "df['pure'] = (df['doc_text']).apply(purify_docs)\n",
    "queries['pure'] = (queries['query_text']).apply(purify_docs)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df['pure'].head())\n",
    "print(queries['pure'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c1b2dc",
   "metadata": {},
   "source": [
    "### 2. We need to correct the spellings in both queries and documents. For each query, which got corrected, we need to display the original and the corrected query on two spearate lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09adda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is problematic!!\n",
    "import contextualSpellCheck\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "contextualSpellCheck.add_to_pipe(nlp)\n",
    "\n",
    "def rectify_sentences(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    return doc._.outcome_spellCheck\n",
    "\n",
    "queries['rectified'] = queries['pure'].apply(rectify_sentences)\n",
    "df['rectified'] = df['pure'].apply(rectify_sentences)\n",
    "\n",
    "for index, row in queries.iterrows():\n",
    "    original_query = row['pure']\n",
    "    corrected_query = row['rectified']\n",
    "    if original_query != corrected_query:\n",
    "        print(f\"Original Query: {original_query}\")\n",
    "        print(f\"Corrected Query: {corrected_query}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.black(\"en\")\n",
    "\n",
    "def derive_tokens(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    tokensList = [token.text for token in doc]\n",
    "    return tokensList\n",
    "\n",
    "docs_df['tokens'] = df['rectified'].apply(derive_tokens)\n",
    "\n",
    "\n",
    "lower_limit = 5\n",
    "upper_limit = 0.85\n",
    "\n",
    "collection = []\n",
    "\n",
    "for tokens in df['tokens']:\n",
    "    for token in tokens:\n",
    "        collection.append(token)\n",
    "        \n",
    "vocab = set(collection)\n",
    "\n",
    "doc_freq = {token: collection.count(token) for token in vocab}\n",
    "\n",
    "filtered_tokens = [token for token in unique_tokens if min_df <= doc_freq[token] <= len(docs_df) * max_df]\n",
    "docs_df['tokens'] = docs_df['tokens'].apply(lambda tokens: [token for token in tokens if token in filtered_tokens])\n",
    "\n",
    "# Create TF-IDF vectors for documents\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_docs = vectorizer.fit_transform(docs_df['rectified'])\n",
    "\n",
    "query_df['tokens'] = query_df['corrected_query'].apply(tokenize)\n",
    "query_df['tokens'] = query_df['tokens'].apply(lambda tokens: [token for token in tokens if token in filtered_tokens])\n",
    "\n",
    "tfidf_matrix_queries = vectorizer.transform(query_df['rec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming tfidf_matrix_docs and tfidf_matrix_queries are already created\n",
    "# Using the TF-IDF vectors from the previous code snippets\n",
    "\n",
    "# Calculate cosine similarity between query vectors and document vectors\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix_queries, tfidf_matrix_docs)\n",
    "\n",
    "# Find the top 5 and top 10 most similar documents for each query\n",
    "top_5_similar_docs_indices = cosine_similarities.argsort(axis=1)[:, -5:][:, ::-1]\n",
    "top_10_similar_docs_indices = cosine_similarities.argsort(axis=1)[:, -10:][:, ::-1]\n",
    "\n",
    "# Assuming you have the 'query' DataFrame with original queries\n",
    "for index, row in query_df.iterrows():\n",
    "    query_text = row['corrected_query']\n",
    "    print(f\"\\nQuery: {query_text}\")\n",
    "\n",
    "    # Retrieve the top 5 most similar documents\n",
    "    top_5_docs_indices = top_5_similar_docs_indices[index]\n",
    "    print(\"\\nTop 5 Most Similar Documents:\")\n",
    "    for i, doc_index in enumerate(top_5_docs_indices, start=1):\n",
    "        doc_text = docs_df.iloc[doc_index]['doc_text']\n",
    "        similarity_score = cosine_similarities[index][doc_index]\n",
    "        print(f\"{i}. Document {doc_index + 1} (Similarity Score: {similarity_score:.4f}): {doc_text}\")\n",
    "\n",
    "    # Retrieve the top 10 most similar documents\n",
    "    top_10_docs_indices = top_10_similar_docs_indices[index]\n",
    "    print(\"\\nTop 10 Most Similar Documents:\")\n",
    "    for i, doc_index in enumerate(top_10_docs_indices, start=1):\n",
    "        doc_text = docs_df.iloc[doc_index]['doc_text']\n",
    "        similarity_score = cosine_similarities[index][doc_index]\n",
    "        print(f\"{i}. Document {doc_index + 1} (Similarity Score: {similarity_score:.4f}): {doc_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d399f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming top_1_similar_docs_indices, top_5_similar_docs_indices, and top_10_similar_docs_indices are already calculated\n",
    "\n",
    "# Initialize variables to store Precision@k scores\n",
    "precision_at_1_sum = 0.0\n",
    "precision_at_5_sum = 0.0\n",
    "precision_at_10_sum = 0.0\n",
    "\n",
    "# Loop through each query\n",
    "for index, row in query_df.iterrows():\n",
    "    relevant_docs = set(qdrel_df[qdrel_df['query_id'] == row['query_id']]['doc_id'])\n",
    "    \n",
    "    # Calculate Precision@1\n",
    "    top_1_docs = set(top_1_similar_docs_indices[index])\n",
    "    precision_at_1 = len(relevant_docs.intersection(top_1_docs)) / 1\n",
    "    precision_at_1_sum += precision_at_1\n",
    "\n",
    "    # Calculate Precision@5\n",
    "    top_5_docs = set(top_5_similar_docs_indices[index])\n",
    "    precision_at_5 = len(relevant_docs.intersection(top_5_docs)) / 5\n",
    "    precision_at_5_sum += precision_at_5\n",
    "\n",
    "    # Calculate Precision@10\n",
    "    top_10_docs = set(top_10_similar_docs_indices[index])\n",
    "    precision_at_10 = len(relevant_docs.intersection(top_10_docs)) / 10\n",
    "    precision_at_10_sum += precision_at_10\n",
    "\n",
    "# Calculate average Precision@k over all queries\n",
    "total_queries = len(query_df)\n",
    "average_precision_at_1 = precision_at_1_sum / total_queries\n",
    "average_precision_at_5 = precision_at_5_sum / total_queries\n",
    "average_precision_at_10 = precision_at_10_sum / total_queries\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average Precision@1: {average_precision_at_1:.4f}\")\n",
    "print(f\"Average Precision@5: {average_precision_at_5:.4f}\")\n",
    "print(f\"Average Precision@10: {average_precision_at_10:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
